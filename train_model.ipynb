{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh_uB3DV1QkJ"
      },
      "source": [
        "## Import các thư viện"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qgQ5EWZQ1QkL",
        "outputId": "ac641221-9c26-4796-a9b2-a29827d93685"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-27 06:01:33.261915: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-05-27 06:01:33.264549: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-05-27 06:01:33.302511: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-05-27 06:01:34.036048: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from keras_nlp.api.models import DebertaV3Preprocessor\n",
        "from keras_nlp.api.models import DebertaV3Classifier\n",
        "import keras_nlp\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfJnGEKx1QkM"
      },
      "source": [
        "#### Tham khảo: https://www.kaggle.com/code/awsaf49/aes-2-0-kerasnlp-starter#%F0%9F%8D%BD%EF%B8%8F-%7C-Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Km1FCM1W1QkM"
      },
      "source": [
        "## Các tham số"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4d-Nc0oM1QkN"
      },
      "outputs": [],
      "source": [
        "# TODO: đổi path file csv\n",
        "data_path = \"train.csv\"\n",
        "# Sử dụng model DeBERTa-V3-Extra-Small-English\n",
        "model_preset = \"deberta_v3_extra_small_en\"\n",
        "max_epochs = 10\n",
        "batch_size = 8\n",
        "shufle = 1000\n",
        "lr = 0.0000003"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn3miHu11QkN"
      },
      "source": [
        "## Các hàm chính để xử lý model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDKg_UT-1QkN"
      },
      "source": [
        "### 1. Tiền xử lý dữ liệu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0QgkLPo1QkN"
      },
      "source": [
        "#### 1.1 Tiền xử lý label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQir1vLe1QkN"
      },
      "source": [
        " Label giá trị trị từ 1-6 (cột score) là dữ liệu categorical.\n",
        " Nhưng để làm bài này, label phải là dữ liệu ordinary\n",
        " Biến đổi label CATEGORICAL SANG ORDINARY bằng cách :\n",
        "\n",
        " Encode label thành một vector nhị phân có độ dài 6, bit i bằng 1 nghĩa là đã thỏa yêu cầu i\n",
        " Các giá trị trong vector CHO BIẾT XÁC SUẤT VỊ TRÍ i THỎA YÊU CẦU i.\n",
        " Từ đó có thể sử dụng CROSS-ENTROPY để sử dụng hàm lỗi so sánh sự tương đồng giữa 2 phân phối.\n",
        "\n",
        " Từ trên ta tạo tính ORDINARY như sau:\n",
        "\n",
        " Bài được chấm điểm 1 <= i <= 6 nghĩa là đã thỏa mãn yêu cầu i, VÀ CŨNG THỎA TẤT CẢ CÁC YÊU CẦU TRƯỚC ĐÓ (<= i),\n",
        " nên các bit trong vector nhãn sẽ = 1 ở các vị trí <= i, và 0 ở các vị trí còn lại.\n",
        " Cách làm này giúp có TÍNH SO SÁNH, vì một khi được điểm j >= i, thì các bit 1 của điểm i cũng = 1 ở trong j\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tNljVSXT1QkN"
      },
      "outputs": [],
      "source": [
        "def label_process(y):\n",
        "    n = len(y)\n",
        "    print()\n",
        "    z = np.zeros((n, 6), \"float32\")\n",
        "    for i in range(n):\n",
        "        s = y[i]\n",
        "        z[i, :s] = 1\n",
        "    return z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utpKpcjB1QkN"
      },
      "source": [
        "#### 1.2 Tiền xử lý đầu vào"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lSCd6cd1QkO"
      },
      "source": [
        "Lý do chúng ta cần thực hiện tiền xử lý đầu vào này là vì mô hình  DeBERTa không lấy văn bản thô làm đầu vào. Thay vào đó, chúng làm việc với cách biểu diễn kiểu số cho văn bản. DebertaV3Preprocessor xử lý các bước cần thiết để chuyển đổi văn bản thô thành các biểu diễn số này, bao gồm chuyển sang kiểu token (chia văn bản thành các từ hoặc từ phụ riêng lẻ) và mã hóa các token này dưới dạng số nguyên. Nó cũng đảm bảo rằng tất cả các chuỗi đầu vào đều có cùng độ dài 512, bằng cách đệm các chuỗi ngắn hơn hoặc cắt bớt các chuỗi dài hơn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IadC8txv1QkO",
        "outputId": "76a76354-fb32-409d-988d-f3126759191f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/deberta_v3/keras/deberta_v3_extra_small_en/2/download/preprocessor.json...\n"
          ]
        }
      ],
      "source": [
        "preprocessor = DebertaV3Preprocessor.from_preset(\n",
        "    preset=model_preset,\n",
        "    sequence_length=512,\n",
        ")\n",
        "\n",
        "def input_process(input, label):\n",
        "    return (preprocessor(input), label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCsnypEl1QkO"
      },
      "source": [
        "### 2. Tạo và cấu hình model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6hnjhfv1QkO"
      },
      "source": [
        "Load model đã được cấu hình và train sẵn, sau đó train để fine-tune model này phù hợp cho bài toán. </br>\n",
        "Như đã nói trên sử đầù ra là một vector độ dài 6, mỗi vị trí cho biết xác suất thỏa yêu cầu i.</br>\n",
        "Đầu ra của mạng sử dụng sigmoid cho ra giá trị 0->1, chuẩn hóa thành xác suất cho mỗi vị trí i.</br>\n",
        "Sử dụng hàm Binary Cross-Entropy, vì ta tính xác suất mỗi vị trí (mỗi vị trí đúng (1) đến sai (0)),\n",
        "sau đó keras.losses.BinaryCrossentropy tổng hợp Loss tại mỗi vị trí làm Loss chung\n",
        "Sử dụng Adam optimizer kết hợp SGD và momentum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WKp3kPHJ1QkO"
      },
      "outputs": [],
      "source": [
        "def create_DebertaV3_model(model_preset):\n",
        "    debertaV3 = DebertaV3Classifier.from_preset(\n",
        "        model_preset, preprocessor=None, num_classes=6\n",
        "    )\n",
        "\n",
        "    #NOTE: Bug ở dòng sau \n",
        "    # inputs = debertaV3.input\n",
        "    # outputs = debertaV3(inputs)\n",
        "\n",
        "    # prob_outputs = keras.layers.Activation(\"sigmoid\")(outputs)\n",
        "    # model = keras.Model(inputs, prob_outputs)\n",
        "\n",
        "    return debertaV3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCRkHXT01QkO"
      },
      "source": [
        "### 3. Tạo dataset cho dữ liệu train và validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9FAuVol1QkO"
      },
      "source": [
        "Load dữ liệu từ file csv và tạo tf.data.Dataset cho dữ liệu train và dữ liệu validation.</br>\n",
        "Dataset load dữ liệu theo lô (và cache để tiết kiệm bộ nhớ trong) và hoán vị dữ liệu sau mỗi vòng lặp cho THUẬT TOÁN SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6VF7ZUcp1QkP"
      },
      "outputs": [],
      "source": [
        "def create_dataset():\n",
        "    df = pd.read_csv(data_path)\n",
        "    X_train_df, X_val_df, y_train_df, y_val_df = train_test_split(\n",
        "        df[\"full_text\"], df[\"score\"], test_size=0.2, stratify=df[\"score\"]\n",
        "    )\n",
        "    X_train = X_train_df.tolist()\n",
        "    X_val = X_val_df.tolist()\n",
        "    y_train = label_process(y_train_df.tolist())\n",
        "    y_val = label_process(y_val_df.tolist())\n",
        "    train_ds = (\n",
        "        tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "        .map(input_process)\n",
        "        .cache()\n",
        "        .shuffle(shufle, seed=0)\n",
        "        .batch(batch_size)\n",
        "    )\n",
        "    opt = tf.data.Options()\n",
        "    opt.experimental_deterministic = False\n",
        "    train_ds = train_ds.with_options(opt)\n",
        "\n",
        "    val_ds = (\n",
        "        tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "        .map(input_process)\n",
        "        .cache()\n",
        "        .batch(batch_size)\n",
        "    )\n",
        "    print(train_ds)\n",
        "    print(val_ds)\n",
        "    return train_ds, val_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsEbWyc41QkP"
      },
      "source": [
        "## Huấn luyện model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-SNyX0z61QkP",
        "outputId": "aa05a417-faf6-49f5-86e7-7503c6bcfa24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/deberta_v3/keras/deberta_v3_extra_small_en/2/download/task.json...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<_OptionsDataset element_spec=({'token_ids': TensorSpec(shape=(None, 512), dtype=tf.int32, name=None), 'padding_mask': TensorSpec(shape=(None, 512), dtype=tf.bool, name=None)}, TensorSpec(shape=(None, 6), dtype=tf.float32, name=None))>\n",
            "<_BatchDataset element_spec=({'token_ids': TensorSpec(shape=(None, 512), dtype=tf.int32, name=None), 'padding_mask': TensorSpec(shape=(None, 512), dtype=tf.bool, name=None)}, TensorSpec(shape=(None, 6), dtype=tf.float32, name=None))>\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1716764531.291348   14996 service.cc:145] XLA service 0x73b53c027600 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1716764531.291393   14996 service.cc:153]   StreamExecutor device (0): Host, Default Version\n",
            "2024-05-27 06:02:13.013097: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2024-05-27 06:02:14.736972: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:580 : INVALID_ARGUMENT: Incompatible shapes: [8,6] vs. [8]\n",
            "\t [[{{node Equal}}]]\n",
            "\ttf2xla conversion failed while converting __inference_one_step_on_data_60932[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n",
            "2024-05-27 06:02:14.737059: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [8,6] vs. [8]\n",
            "\t [[{{node Equal}}]]\n",
            "\ttf2xla conversion failed while converting __inference_one_step_on_data_60932[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n",
            "\t [[StatefulPartitionedCall]]\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "pybind11::error_already_set: MISMATCH of original and normalized active exception types: ORIGINAL InvalidArgumentError REPLACED BY KeyboardInterrupt: <EMPTY MESSAGE>\n\nAt:\n  /home/decade/.local/lib/python3.10/site-packages/tensorflow/python/framework/errors_impl.py(284): __init__\n  /home/decade/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py(53): quick_execute\n  /home/decade/.local/lib/python3.10/site-packages/tensorflow/python/eager/context.py(1500): call_function\n  /home/decade/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py(251): call_flat\n  /home/decade/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py(216): call_preflattened\n  /home/decade/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py(1322): _call_flat\n  /home/decade/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py(919): _call\n  /home/decade/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py(833): __call__\n  /home/decade/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py(150): error_handler\n  /home/decade/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py(314): fit\n  /home/decade/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py(117): error_handler\n  /home/decade/.local/lib/python3.10/site-packages/keras_nlp/src/utils/pipeline_model.py(194): fit\n  /tmp/ipykernel_14956/267153124.py(18): <module>\n  /home/decade/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py(3577): run_code\n  /home/decade/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py(3517): run_ast_nodes\n  /home/decade/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py(3334): run_cell_async\n  /home/decade/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n  /home/decade/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py(3130): _run_cell\n  /home/decade/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py(3075): run_cell\n  /home/decade/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py(549): run_cell\n  /home/decade/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py(446): do_execute\n  /home/decade/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py(778): execute_request\n  /home/decade/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py(359): execute_request\n  /home/decade/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py(437): dispatch_shell\n  /home/decade/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py(534): process_one\n  /home/decade/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py(545): dispatch_queue\n  /usr/lib/python3.10/asyncio/events.py(80): _run\n  /usr/lib/python3.10/asyncio/base_events.py(1909): _run_once\n  /usr/lib/python3.10/asyncio/base_events.py(603): run_forever\n  /home/decade/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py(205): start\n  /home/decade/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py(739): start\n  /home/decade/.local/lib/python3.10/site-packages/traitlets/config/application.py(1075): launch_instance\n  /home/decade/.local/lib/python3.10/site-packages/ipykernel_launcher.py(18): <module>\n  /usr/lib/python3.10/runpy.py(86): _run_code\n  /usr/lib/python3.10/runpy.py(196): _run_module_as_main\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 18\u001b[0m\n\u001b[1;32m     10\u001b[0m save_model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# HDF5\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msave_model\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras_nlp/src/utils/pipeline_model.py:194\u001b[0m, in \u001b[0;36mPipelineModel.fit\u001b[0;34m(self, x, y, batch_size, sample_weight, validation_data, validation_split, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m         (vx, vy, vsw) \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munpack_x_y_sample_weight(\n\u001b[1;32m    188\u001b[0m             validation_data\n\u001b[1;32m    189\u001b[0m         )\n\u001b[1;32m    190\u001b[0m         validation_data \u001b[38;5;241m=\u001b[39m _convert_inputs_to_dataset(\n\u001b[1;32m    191\u001b[0m             vx, vy, vsw, batch_size\n\u001b[1;32m    192\u001b[0m         )\n\u001b[0;32m--> 194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mRuntimeError\u001b[0m: pybind11::error_already_set: MISMATCH of original and normalized active exception types: ORIGINAL InvalidArgumentError REPLACED BY KeyboardInterrupt: <EMPTY MESSAGE>\n\nAt:\n  /home/decade/.local/lib/python3.10/site-packages/tensorflow/python/framework/errors_impl.py(284): __init__\n  /home/decade/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py(53): quick_execute\n  /home/decade/.local/lib/python3.10/site-packages/tensorflow/python/eager/context.py(1500): call_function\n  /home/decade/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py(251): call_flat\n  /home/decade/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py(216): call_preflattened\n  /home/decade/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py(1322): _call_flat\n  /home/decade/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py(919): _call\n  /home/decade/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py(833): __call__\n  /home/decade/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py(150): error_handler\n  /home/decade/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py(314): fit\n  /home/decade/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py(117): error_handler\n  /home/decade/.local/lib/python3.10/site-packages/keras_nlp/src/utils/pipeline_model.py(194): fit\n  /tmp/ipykernel_14956/267153124.py(18): <module>\n  /home/decade/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py(3577): run_code\n  /home/decade/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py(3517): run_ast_nodes\n  /home/decade/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py(3334): run_cell_async\n  /home/decade/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n  /home/decade/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py(3130): _run_cell\n  /home/decade/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py(3075): run_cell\n  /home/decade/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py(549): run_cell\n  /home/decade/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py(446): do_execute\n  /home/decade/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py(778): execute_request\n  /home/decade/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py(359): execute_request\n  /home/decade/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py(437): dispatch_shell\n  /home/decade/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py(534): process_one\n  /home/decade/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py(545): dispatch_queue\n  /usr/lib/python3.10/asyncio/events.py(80): _run\n  /usr/lib/python3.10/asyncio/base_events.py(1909): _run_once\n  /usr/lib/python3.10/asyncio/base_events.py(603): run_forever\n  /home/decade/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py(205): start\n  /home/decade/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py(739): start\n  /home/decade/.local/lib/python3.10/site-packages/traitlets/config/application.py(1075): launch_instance\n  /home/decade/.local/lib/python3.10/site-packages/ipykernel_launcher.py(18): <module>\n  /usr/lib/python3.10/runpy.py(86): _run_code\n  /usr/lib/python3.10/runpy.py(196): _run_module_as_main\n"
          ]
        }
      ],
      "source": [
        "train_ds, val_ds = create_dataset()\n",
        "model = create_DebertaV3_model(model_preset)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(lr),\n",
        "    loss=keras.losses.BinaryCrossentropy(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")],\n",
        "    jit_compile=True,\n",
        ")\n",
        "save_model = keras.callbacks.ModelCheckpoint(\n",
        "    \"model.weights.h5\",  # HDF5\n",
        "    monitor=\"val_loss\",\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True,\n",
        "    mode=\"min\",\n",
        ")\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    x = train_ds,\n",
        "    epochs=max_epochs,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[save_model],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul-p4y5A1QkP"
      },
      "source": [
        "## Thống kê lỗi và đánh giá"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIsZT_V61QkQ"
      },
      "outputs": [],
      "source": [
        "training_loss = history.history[\"loss\"]\n",
        "validation_loss = history.history[\"val_loss\"]\n",
        "\n",
        "epoch_rows = range(1, len(training_loss) + 1)\n",
        "plt.plot(epoch_rows, training_loss, \"r--\")\n",
        "plt.plot(epoch_rows, validation_loss, \"b-\")\n",
        "plt.legend([\"Training Loss\", \"Validation Loss\"])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.savefig(\"Loss_plot.png\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
